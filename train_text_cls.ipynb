{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of words to combine\n",
    "adjectives = [\n",
    "    \"Ancient\",\n",
    "    \"Modern\",\n",
    "    \"Eternal\",\n",
    "    \"Mystic\",\n",
    "    \"Golden\",\n",
    "    \"Emerald\",\n",
    "    \"Silent\",\n",
    "    \"Royal\",\n",
    "]\n",
    "nouns = [\"Dragon\", \"Lotus\", \"Phoenix\", \"River\", \"Mountain\", \"Sea\", \"Forest\", \"Sky\"]\n",
    "business_types = [\n",
    "    \"Café\",\n",
    "    \"Bakery\",\n",
    "    \"Restaurant\",\n",
    "    \"Boutique\",\n",
    "    \"Salon\",\n",
    "    \"Bookstore\",\n",
    "    \"Gallery\",\n",
    "    \"Market\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of Vietnamese words to combine\n",
    "adjectives = [\n",
    "    \"Cổ Kính\",\n",
    "    \"Hiện Đại\",\n",
    "    \"Vĩnh Cửu\",\n",
    "    \"Huyền Bí\",\n",
    "    \"Vàng\",\n",
    "    \"Ngọc Bích\",\n",
    "    \"Yên Tĩnh\",\n",
    "    \"Hoàng Gia\",\n",
    "]\n",
    "nouns = [\"Rồng\", \"Sen\", \"Phượng\", \"Sông\", \"Núi\", \"Biển\", \"Rừng\", \"Bầu Trời\"]\n",
    "business_types = [\n",
    "    \"Quán Cà Phê\",\n",
    "    \"Tiệm Bánh\",\n",
    "    \"Nhà Hàng\",\n",
    "    \"Cửa Hàng\",\n",
    "    \"Salon Tóc\",\n",
    "    \"Hiệu Sách\",\n",
    "    \"Phòng Trưng Bày\",\n",
    "    \"Chợ\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to generate names\n",
    "def generate_business_names(num_names):\n",
    "    generated_names = []\n",
    "    for _ in range(num_names):\n",
    "        adjective = random.choice(adjectives)\n",
    "        noun = random.choice(nouns)\n",
    "        business_type = random.choice(business_types)\n",
    "        name = f\"{business_type} {adjective} {noun}\"\n",
    "        generated_names.append(name)\n",
    "    return generated_names\n",
    "\n",
    "\n",
    "# Generate 500 business names\n",
    "business_names = generate_business_names(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Châu, Sơn Động, Bắc Giang Azure Apparel 7345831361\n"
     ]
    }
   ],
   "source": [
    "def load_texts(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return [line[:-1] for line in lines]\n",
    "\n",
    "\n",
    "addresses = load_texts(\"signboard_text_dataset/addresses.txt\")\n",
    "names = load_texts(\"signboard_text_dataset/names.txt\")\n",
    "phone_numbers = load_texts(\"signboard_text_dataset/phone_numbers.txt\")\n",
    "print(addresses[0], names[0], phone_numbers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Apparel || An Chau, Son Dong, Bac Giang\n"
     ]
    }
   ],
   "source": [
    "def remove_accents(X):\n",
    "    X_new = X.copy()\n",
    "    for i, row in enumerate(X):\n",
    "        X_new[i] = unidecode(row)\n",
    "    return X_new\n",
    "\n",
    "\n",
    "names = remove_accents(names)\n",
    "addresses = remove_accents(addresses)\n",
    "print(names[0], \"||\", addresses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2403, 1) (2403, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((names, addresses, phone_numbers), axis=0).reshape(-1, 1)\n",
    "y = np.array(\n",
    "    [0] * len(names) + [1] * len(addresses) + [2] * len(phone_numbers)\n",
    ").reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2162, 1) (2162, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer = tf.keras.layers.TextVectorization(\n",
    "    split=\"character\",\n",
    "    # standardize=\"lower\",\n",
    ")\n",
    "text_vec_layer.adapt([X])\n",
    "vocab_size = text_vec_layer.vocabulary_size()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the config and weights\n",
    "import pickle\n",
    "\n",
    "pickle.dump(\n",
    "    {\"config\": text_vec_layer.get_config(), \"weights\": text_vec_layer.get_weights()},\n",
    "    open(\"tv_layer.pkl\", \"wb\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " ' ',\n",
       " 'n',\n",
       " 'a',\n",
       " 'h',\n",
       " 'o',\n",
       " 'i',\n",
       " 'u',\n",
       " 'e',\n",
       " 'g',\n",
       " 't',\n",
       " 'c',\n",
       " 'r',\n",
       " 'l',\n",
       " 's',\n",
       " '3',\n",
       " '4',\n",
       " '9',\n",
       " '0',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '1',\n",
       " '8',\n",
       " '2',\n",
       " 'b',\n",
       " 'd',\n",
       " 'm',\n",
       " 'y',\n",
       " 'p',\n",
       " 'k',\n",
       " 'v',\n",
       " 'q',\n",
       " 'f',\n",
       " 'x',\n",
       " 'w',\n",
       " 'j',\n",
       " 'z']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = text_vec_layer(X_train)\n",
    "X_test_encoded = text_vec_layer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.7003INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 17s 206ms/step - loss: 0.6108 - accuracy: 0.7003 - val_loss: 0.3273 - val_accuracy: 0.8838\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.8663INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 14s 205ms/step - loss: 0.3184 - accuracy: 0.8663 - val_loss: 0.2612 - val_accuracy: 0.8963\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.8922INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 14s 204ms/step - loss: 0.2698 - accuracy: 0.8922 - val_loss: 0.2025 - val_accuracy: 0.9253\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.2536 - accuracy: 0.8992 - val_loss: 0.2143 - val_accuracy: 0.9253\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.9167INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 13s 187ms/step - loss: 0.2190 - accuracy: 0.9167 - val_loss: 0.1833 - val_accuracy: 0.9295\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 7s 105ms/step - loss: 0.2188 - accuracy: 0.9144 - val_loss: 0.1823 - val_accuracy: 0.9295\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 7s 105ms/step - loss: 0.2061 - accuracy: 0.9241 - val_loss: 0.1973 - val_accuracy: 0.9129\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 7s 100ms/step - loss: 0.1971 - accuracy: 0.9209 - val_loss: 0.1835 - val_accuracy: 0.9295\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.9237INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gru_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 13s 199ms/step - loss: 0.1897 - accuracy: 0.9237 - val_loss: 0.1607 - val_accuracy: 0.9378\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 7s 105ms/step - loss: 0.1668 - accuracy: 0.9292 - val_loss: 0.1342 - val_accuracy: 0.9378\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size,\n",
    "            output_dim=16,\n",
    "            mask_zero=True,\n",
    "        ),\n",
    "        tf.keras.layers.GRU(128),\n",
    "        tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"gru_model\", monitor=\"val_accuracy\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=10\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train_encoded,\n",
    "    tf.constant(y_train),\n",
    "    validation_data=(X_test_encoded, tf.constant(y_test)),\n",
    "    epochs=10,\n",
    "    callbacks=[model_ckpt, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text_vec_layer([\"Bun bo Hue\"]), verbose=False).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_disk = pickle.load(open(\"tv_layer.pkl\", \"rb\"))\n",
    "new_v = tf.keras.layers.TextVectorization(\n",
    "    split=\"character\",\n",
    "    # standardize=\"lower\",\n",
    ")\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "# new_v.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "new_v.set_weights(from_disk[\"weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max((new_v([X_train[100]]) - text_vec_layer([X_train[100]]))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 18:40:58.782637: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:58.796649: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.275142: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.287779: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.454380: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.464747: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.636520: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.648367: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.747028: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n",
      "2024-07-04 18:40:59.756712: W tensorflow/core/common_runtime/graph_constructor.cc:840] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 40 outputs. Output shapes may be inaccurate.\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(\"gru_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = [\n",
    "    \"Sữa chua Hạ Long\",\n",
    "    \"Đường Thiện Khánh, Bích Nhôi 3, Minh Tân, Kinh Môn, Hải Dương\",\n",
    "    \"ĐT: 0375565858\",\n",
    "]\n",
    "new_model.predict(new_v(samples), verbose=False).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hihi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
